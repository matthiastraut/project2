{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53b42c5",
   "metadata": {},
   "source": [
    "# This notebook trains the model for the aircraft classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8449a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnx\n",
    "import onnxscript\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a7e03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use hardware acceleration if available\n",
    "if torch.cuda.is_available(): \n",
    "    device = torch.device(\"cuda\") \n",
    "elif torch.mps.is_available(): \n",
    "    device = torch.device(\"mps\")\n",
    "else: \n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af06d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file\n",
    "!wget https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz\n",
    "# Extract the tar.gz file\n",
    "!tar -xvzf fgvc-aircraft-2013b.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfec342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load an image as test\n",
    "img = Image.open('fgvc-aircraft-2013b/data/images/2251118.jpg')\n",
    "\n",
    "# Resize to target size\n",
    "img = img.resize((300, 200))\n",
    "\n",
    "# Convert to numpy array\n",
    "x = np.array(img)\n",
    "print(x.shape)  # (200, 300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154a6ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[150, 154, 174],\n",
       "        [151, 155, 174],\n",
       "        [151, 155, 175],\n",
       "        ...,\n",
       "        [123, 146, 178],\n",
       "        [125, 145, 178],\n",
       "        [124, 146, 178]],\n",
       "\n",
       "       [[151, 155, 174],\n",
       "        [153, 155, 175],\n",
       "        [153, 156, 175],\n",
       "        ...,\n",
       "        [124, 146, 180],\n",
       "        [126, 145, 178],\n",
       "        [126, 146, 179]],\n",
       "\n",
       "       [[152, 156, 175],\n",
       "        [154, 155, 175],\n",
       "        [154, 155, 175],\n",
       "        ...,\n",
       "        [123, 147, 179],\n",
       "        [124, 147, 179],\n",
       "        [125, 147, 179]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 85,  87,  92],\n",
       "        [ 68,  71,  75],\n",
       "        [ 79,  82,  87],\n",
       "        ...,\n",
       "        [ 89, 110, 122],\n",
       "        [ 43,  49,  54],\n",
       "        [ 28,  31,  35]],\n",
       "\n",
       "       [[ 75,  82,  87],\n",
       "        [  2,   3,   4],\n",
       "        [ 18,  20,  22],\n",
       "        ...,\n",
       "        [ 47,  60,  68],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[ 46,  52,  59],\n",
       "        [ 41,  47,  55],\n",
       "        [ 46,  54,  61],\n",
       "        ...,\n",
       "        [ 12,  14,  16],\n",
       "        [  0,   0,   0],\n",
       "        [  1,   0,   0]]], shape=(200, 300, 3), dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00f3e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a data loader class\n",
    "\n",
    "class AircraftDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(data_dir, f'{img_name}.jpg') for img_name in labels.keys()]\n",
    "        self.classes = sorted(list(set(labels.values())))\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        self.labels = [self.class_to_idx[label] for label in labels.values()]\n",
    "\n",
    "        #for label_name in self.classes:\n",
    "        #   label_dir = os.path.join(data_dir, label_name)\n",
    "        #    for img_name in self.labels[label_name].keys():\n",
    "        #        self.image_paths.append(os.path.join(data_dir, img_name))\n",
    "        #        self.labels.append(self.class_to_idx[label_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7641782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use ImageNet-like preprocessing\n",
    "\n",
    "input_size = (300, 200)\n",
    "\n",
    "# ImageNet normalization values\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Simple transforms - just resize and normalize\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((input_size[0], input_size[1])),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((input_size[0], input_size[1])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef14bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "\n",
    "for type in ['train', 'test', 'val']:\n",
    "    with open(f'fgvc-aircraft-2013b/data/images_family_{type}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    lines = [line.strip() for line in lines]\n",
    "\n",
    "    labels[type] = {line[:7]: line[8:] for line in lines}\n",
    "\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44a9347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our DataLoader to load the dataset \n",
    "\n",
    "train_dataset = AircraftDataset(\n",
    "    data_dir='./fgvc-aircraft-2013b/data/images',\n",
    "    labels=labels['train'],\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "val_dataset = AircraftDataset(\n",
    "    data_dir='./fgvc-aircraft-2013b/data/images',\n",
    "    labels=labels['val'],\n",
    "    transform=val_transforms\n",
    ")\n",
    "\n",
    "test_dataset = AircraftDataset(\n",
    "    data_dir='./fgvc-aircraft-2013b/data/images',\n",
    "    labels=labels['test'],\n",
    "    transform=val_transforms\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff20e51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8, 21, 40, 36, 37, 35,  3, 49, 58, 43,  4, 56, 53, 15, 24, 54, 45, 19,\n",
       "         62,  7, 26, 37, 16, 15,  0, 48, 49, 62, 23, 15,  9, 17]),\n",
       " torch.Size([32, 3, 300, 200]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if images have been loaded\n",
    "N = 1  \n",
    "dataiter = iter(train_loader)\n",
    "\n",
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "for i in range(0, N): \n",
    "  image, label = next(dataiter)\n",
    "  image_list.append(image)\n",
    "  label_list.append(label)\n",
    "\n",
    "label, image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f753bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(list(set(labels['train'].values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd87cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "# We played with different versions of the model, which led to the addition\n",
    "# of transforms.RandomHorizontalFlip() and transforms.RandomRotation(5) above:\n",
    "num_classes = len(sorted(list(set(labels['train'].values()))))\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # Block 1: Initial feature extraction\n",
    "    # We start with 32 filters to catch basic edges/textures\n",
    "    nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32), # Normalizes activations\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2), # Output: 32 x 150 x 100\n",
    "    \n",
    "    # Block 2: Catching shapes\n",
    "    nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2), # Output: 64 x 75 x 50\n",
    "    \n",
    "    # Block 3: Complex features (wing shapes, engines)\n",
    "    nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2), # Output: 128 x 37 x 25\n",
    "    \n",
    "    # Feature Reduction\n",
    "    # Adaptive pooling allows the model to work regardless of input size\n",
    "    # and reduces the 37x25 dimensions to 1x1\n",
    "    nn.AdaptiveAvgPool2d((1, 1)), \n",
    "    nn.Flatten(),\n",
    "    \n",
    "    # Classification Head\n",
    "    nn.Linear(128, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5), # Prevents neurons from co-depending too much\n",
    "    nn.Linear(256, num_classes)\n",
    "    # Note: No Softmax here if using nn.CrossEntropyLoss\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aa0328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train() # Set to training mode (enables Dropout/BatchNorm)\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # 1. Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 2. Backward pass\n",
    "        optimizer.zero_grad() # Reset gradients\n",
    "        loss.backward()       # Compute gradients\n",
    "        optimizer.step()      # Update weights\n",
    "        \n",
    "        # Metrics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval() # Set to evaluation mode (disables Dropout/BatchNorm)\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad(): # No gradient calculation for validation\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "    return running_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1623454",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def make_model(learning_rate=0.001):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Learning rate: 0.001 ----\n",
      "Epoch 1/3:\n",
      "  Train Loss: 4.0910 | Acc: 6.72%\n",
      "  Val Loss:   3.9944 | Acc: 8.01%\n",
      "Epoch 2/3:\n",
      "  Train Loss: 3.9980 | Acc: 7.59%\n",
      "  Val Loss:   3.9572 | Acc: 7.86%\n",
      "Epoch 3/3:\n",
      "  Train Loss: 3.9467 | Acc: 8.31%\n",
      "  Val Loss:   3.9128 | Acc: 8.67%\n",
      "---- Learning rate: 0.01 ----\n",
      "Epoch 1/3:\n",
      "  Train Loss: 4.1056 | Acc: 7.20%\n",
      "  Val Loss:   3.9975 | Acc: 8.04%\n",
      "Epoch 2/3:\n",
      "  Train Loss: 4.0456 | Acc: 7.62%\n",
      "  Val Loss:   3.9935 | Acc: 8.22%\n",
      "Epoch 3/3:\n",
      "  Train Loss: 4.0217 | Acc: 8.28%\n",
      "  Val Loss:   3.9789 | Acc: 8.25%\n",
      "---- Learning rate: 0.1 ----\n",
      "Epoch 1/3:\n",
      "  Train Loss: 4.1559 | Acc: 7.68%\n",
      "  Val Loss:   4.0910 | Acc: 8.01%\n",
      "Epoch 2/3:\n",
      "  Train Loss: 4.1122 | Acc: 7.80%\n",
      "  Val Loss:   4.0874 | Acc: 8.01%\n",
      "Epoch 3/3:\n",
      "  Train Loss: 4.1066 | Acc: 8.01%\n",
      "  Val Loss:   4.0970 | Acc: 8.01%\n"
     ]
    }
   ],
   "source": [
    "# Let's try different learning rates\n",
    "\n",
    "for learning_rate in [0.001, 0.01, 0.1]:\n",
    "    \n",
    "    print(f'---- Learning rate: {learning_rate} ----')\n",
    "\n",
    "    model, optimizer = make_model(\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    num_epochs = 3\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Acc: {train_acc:.2%}\")\n",
    "        print(f\"  Val Loss:   {val_loss:.4f} | Acc: {val_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc184b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Train Loss: 4.0942 | Acc: 7.38%\n",
      "  Val Loss:   3.9852 | Acc: 8.01%\n",
      "Epoch 2/10:\n",
      "  Train Loss: 3.9801 | Acc: 8.10%\n",
      "  Val Loss:   3.9499 | Acc: 8.52%\n",
      "Epoch 3/10:\n",
      "  Train Loss: 3.9518 | Acc: 7.98%\n",
      "  Val Loss:   3.9252 | Acc: 8.52%\n",
      "Epoch 4/10:\n",
      "  Train Loss: 3.9083 | Acc: 8.55%\n",
      "  Val Loss:   3.8923 | Acc: 9.24%\n",
      "Epoch 5/10:\n",
      "  Train Loss: 3.8817 | Acc: 8.88%\n",
      "  Val Loss:   3.8637 | Acc: 9.12%\n",
      "Epoch 6/10:\n",
      "  Train Loss: 3.8456 | Acc: 8.97%\n",
      "  Val Loss:   3.8514 | Acc: 9.21%\n",
      "Epoch 7/10:\n",
      "  Train Loss: 3.8215 | Acc: 9.51%\n",
      "  Val Loss:   3.8540 | Acc: 9.09%\n",
      "Epoch 8/10:\n",
      "  Train Loss: 3.7944 | Acc: 9.30%\n",
      "  Val Loss:   3.8269 | Acc: 9.36%\n",
      "Epoch 9/10:\n",
      "  Train Loss: 3.7410 | Acc: 10.41%\n",
      "  Val Loss:   3.7951 | Acc: 9.60%\n",
      "Epoch 10/10:\n",
      "  Train Loss: 3.7133 | Acc: 10.38%\n",
      "  Val Loss:   3.7578 | Acc: 10.56%\n"
     ]
    }
   ],
   "source": [
    "# Based on our testing above, we settle on a learning rate of 0.001\n",
    "\n",
    "\n",
    "model, optimizer = make_model(\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Step the scheduler\n",
    "    # scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Acc: {train_acc:.2%}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Acc: {val_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3094447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test Loss: 3.7578 | Acc: 10.56%\n"
     ]
    }
   ],
   "source": [
    "# Let's apply the model to the test set\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "print(f\"  Test Loss: {test_loss:.4f} | Acc: {test_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a92c28fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0121 21:29:53.377000 66454 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 14 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `Sequential([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `Sequential([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 14).\n",
      "Failed to convert the model to the target version 14 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthiastraut/Courses/Zoomcamp_ML/Homeworks/project2/.venv/lib/python3.12/site-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/matthiastraut/Courses/Zoomcamp_ML/Homeworks/project2/.venv/lib/python3.12/site-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/Users/matthiastraut/Courses/Zoomcamp_ML/Homeworks/project2/.venv/lib/python3.12/site-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/matthiastraut/Courses/Zoomcamp_ML/Homeworks/project2/.venv/lib/python3.12/site-packages/onnx/version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: /Users/runner/work/onnx/onnx/onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 3 of general pattern rewrite rules.\n"
     ]
    }
   ],
   "source": [
    "# Saving the model to ONNX format\n",
    "import json\n",
    "\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "example_inputs = torch.randn(1, 3, 300, 200).to(\"cpu\")\n",
    "torch.onnx.export(model, example_inputs, \"model.onnx\", export_params=True, opset_version=14)\n",
    "\n",
    "onnx_model = onnx.load(\"model.onnx\")\n",
    "class_names = sorted(list(set(labels['train'].values()))) # Our list of 70 names\n",
    "meta = onnx_model.metadata_props.add()\n",
    "meta.key = \"class_names\"\n",
    "meta.value = json.dumps(class_names)\n",
    "onnx.save(onnx_model, \"model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eaa98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
