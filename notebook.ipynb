{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53b42c5",
   "metadata": {},
   "source": [
    "# This notebook trains the model for the aircraft classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8449a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnx\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a7e03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use hardware acceleration if available\n",
    "if torch.cuda.is_available(): \n",
    "    device = torch.device(\"cuda\") \n",
    "elif torch.mps.is_available(): \n",
    "    device = torch.device(\"mps\")\n",
    "else: \n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af06d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file\n",
    "!wget https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz\n",
    "# Extract the tar.gz file\n",
    "!tar -xvzf fgvc-aircraft-2013b.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfec342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load an image as test\n",
    "img = Image.open('fgvc-aircraft-2013b/data/images/2251118.jpg')\n",
    "\n",
    "# Resize to target size\n",
    "img = img.resize((300, 200))\n",
    "\n",
    "# Convert to numpy array\n",
    "x = np.array(img)\n",
    "print(x.shape)  # (200, 300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154a6ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[150, 154, 174],\n",
       "        [151, 155, 174],\n",
       "        [151, 155, 175],\n",
       "        ...,\n",
       "        [123, 146, 178],\n",
       "        [125, 145, 178],\n",
       "        [124, 146, 178]],\n",
       "\n",
       "       [[151, 155, 174],\n",
       "        [153, 155, 175],\n",
       "        [153, 156, 175],\n",
       "        ...,\n",
       "        [124, 146, 180],\n",
       "        [126, 145, 178],\n",
       "        [126, 146, 179]],\n",
       "\n",
       "       [[152, 156, 175],\n",
       "        [154, 155, 175],\n",
       "        [154, 155, 175],\n",
       "        ...,\n",
       "        [123, 147, 179],\n",
       "        [124, 147, 179],\n",
       "        [125, 147, 179]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 85,  87,  92],\n",
       "        [ 68,  71,  75],\n",
       "        [ 79,  82,  87],\n",
       "        ...,\n",
       "        [ 89, 110, 122],\n",
       "        [ 43,  49,  54],\n",
       "        [ 28,  31,  35]],\n",
       "\n",
       "       [[ 75,  82,  87],\n",
       "        [  2,   3,   4],\n",
       "        [ 18,  20,  22],\n",
       "        ...,\n",
       "        [ 47,  60,  68],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[ 46,  52,  59],\n",
       "        [ 41,  47,  55],\n",
       "        [ 46,  54,  61],\n",
       "        ...,\n",
       "        [ 12,  14,  16],\n",
       "        [  0,   0,   0],\n",
       "        [  1,   0,   0]]], shape=(200, 300, 3), dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00f3e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a data loader class\n",
    "\n",
    "class AircraftDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(data_dir, f'{img_name}.jpg') for img_name in labels.keys()]\n",
    "        self.classes = sorted(list(set(labels.values())))\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        self.labels = [self.class_to_idx[label] for label in labels.values()]\n",
    "\n",
    "        #for label_name in self.classes:\n",
    "        #   label_dir = os.path.join(data_dir, label_name)\n",
    "        #    for img_name in self.labels[label_name].keys():\n",
    "        #        self.image_paths.append(os.path.join(data_dir, img_name))\n",
    "        #        self.labels.append(self.class_to_idx[label_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7641782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use ImageNet-like preprocessing\n",
    "\n",
    "input_size = (300, 200)\n",
    "\n",
    "# ImageNet normalization values\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Simple transforms - just resize and normalize\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((input_size[0], input_size[1])),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((input_size[0], input_size[1])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef14bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "\n",
    "for type in ['train', 'test', 'val']:\n",
    "    with open(f'fgvc-aircraft-2013b/data/images_family_{type}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    lines = [line.strip() for line in lines]\n",
    "\n",
    "    labels[type] = {line[:7]: line[8:] for line in lines}\n",
    "\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44a9347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our DataLoader to load the dataset \n",
    "\n",
    "train_dataset = AircraftDataset(\n",
    "    data_dir='./fgvc-aircraft-2013b/data/images',\n",
    "    labels=labels['train'],\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "val_dataset = AircraftDataset(\n",
    "    data_dir='./fgvc-aircraft-2013b/data/images',\n",
    "    labels=labels['val'],\n",
    "    transform=val_transforms\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff20e51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([19, 36, 15, 18, 15, 58,  2, 36, 16, 51, 66, 37, 15, 15, 45, 50,  5,  1,\n",
       "         65,  5, 20, 63, 22, 16, 51, 57, 54, 54,  6, 19, 15,  9]),\n",
       " torch.Size([32, 3, 300, 200]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if images have been loaded\n",
    "N = 1  \n",
    "dataiter = iter(train_loader)\n",
    "\n",
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "for i in range(0, N): \n",
    "  image, label = next(dataiter)\n",
    "  image_list.append(image)\n",
    "  label_list.append(label)\n",
    "\n",
    "label, image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f753bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(list(set(labels['train'].values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "# We played with different versions of the model, which led to the addition\n",
    "# of transforms.RandomHorizontalFlip() and transforms.RandomRotation(5) above:\n",
    "num_classes = len(sorted(list(set(labels['train'].values()))))\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # Block 1: Initial feature extraction\n",
    "    # We start with 32 filters to catch basic edges/textures\n",
    "    nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32), # Normalizes activations\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2), # Output: 32 x 150 x 100\n",
    "    \n",
    "    # Block 2: Catching shapes\n",
    "    nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2), # Output: 64 x 75 x 50\n",
    "    \n",
    "    # Block 3: Complex features (wing shapes, engines)\n",
    "    nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2), # Output: 128 x 37 x 25\n",
    "    \n",
    "    # Feature Reduction\n",
    "    # Adaptive pooling allows the model to work regardless of input size\n",
    "    # and reduces the 37x25 spatial dimensions to 1x1\n",
    "    nn.AdaptiveAvgPool2d((1, 1)), \n",
    "    nn.Flatten(),\n",
    "    \n",
    "    # Classification Head\n",
    "    nn.Linear(128, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5), # Prevents neurons from co-depending too much\n",
    "    nn.Linear(256, num_classes)\n",
    "    # Note: No Softmax here if using nn.CrossEntropyLoss\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aa0328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train() # Set to training mode (enables Dropout/BatchNorm)\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # 1. Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 2. Backward pass\n",
    "        optimizer.zero_grad() # Reset gradients\n",
    "        loss.backward()       # Compute gradients\n",
    "        optimizer.step()      # Update weights\n",
    "        \n",
    "        # Metrics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval() # Set to evaluation mode (disables Dropout/BatchNorm)\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad(): # No gradient calculation for validation\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "    return running_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:\n",
      "  Train Loss: 4.0866 | Acc: 8.01%\n",
      "  Val Loss:   4.0734 | Acc: 7.98%\n"
     ]
    }
   ],
   "source": [
    "# Let's try different learning rates\n",
    "\n",
    "for learning_rate in [0.001, 0.01, 0.1]:\n",
    "    \n",
    "    print(f'---- Learning rate: {learning_rate} ----')\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def make_model(learning_rate=0.001):\n",
    "        model.to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        return model, optimizer\n",
    "\n",
    "    model, optimizer = make_model(\n",
    "        learning_rate=learning_rate,\n",
    "        # size_inner=100,\n",
    "        #droprate=0.2,\n",
    "    )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    num_epochs = 1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Acc: {train_acc:.2%}\")\n",
    "        print(f\"  Val Loss:   {val_loss:.4f} | Acc: {val_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc184b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Learning rate: 0.001 ----\n",
      "Epoch 1/1:\n",
      "  Train Loss: 4.0861 | Acc: 7.38%\n",
      "  Val Loss:   3.9839 | Acc: 7.98%\n",
      "---- Learning rate: 0.01 ----\n",
      "Epoch 1/1:\n",
      "  Train Loss: 4.1148 | Acc: 7.47%\n",
      "  Val Loss:   4.0225 | Acc: 8.01%\n",
      "---- Learning rate: 0.1 ----\n",
      "Epoch 1/1:\n",
      "  Train Loss: 4.1559 | Acc: 7.47%\n",
      "  Val Loss:   4.0905 | Acc: 7.98%\n"
     ]
    }
   ],
   "source": [
    "# We settle on a learning rate of 0.01\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def make_model(learning_rate=0.001):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return model, optimizer\n",
    "\n",
    "model, optimizer = make_model(\n",
    "    learning_rate=0.01,\n",
    "    #size_inner=100,\n",
    "    #droprate=0.2,\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Acc: {train_acc:.2%}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Acc: {val_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c28fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'metadata_props'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m model.eval()\n\u001b[32m      7\u001b[39m class_names = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(labels[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m].values()))) \u001b[38;5;66;03m# Your list of 70 names\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m meta = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetadata_props\u001b[49m.add()\n\u001b[32m      9\u001b[39m meta.key = \u001b[33m\"\u001b[39m\u001b[33mclass_names\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m meta.value = json.dumps(class_names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python312/lib/python3.12/site-packages/torch/nn/modules/module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'Sequential' object has no attribute 'metadata_props'"
     ]
    }
   ],
   "source": [
    "# Saving the model to ONNX format\n",
    "import json\n",
    "\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "class_names = sorted(list(set(labels['train'].values()))) # Your list of 70 names\n",
    "meta = model.metadata_props.add()\n",
    "meta.key = \"class_names\"\n",
    "meta.value = json.dumps(class_names)\n",
    "\n",
    "# Create example inputs for exporting the model. The inputs should be a tuple of tensors.\n",
    "example_inputs = torch.randn(1, 3, 300, 200).to(\"cpu\")\n",
    "torch.onnx.export(model, example_inputs, \"model.onnx\", export_params=True, opset_version=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eaa98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
